Changes
------
0.0.24.
  o Added support for data feeds domain_names_dropped_whois_archive
  	and ngtlds_domain_names_dropped_whois_archive

0.0.23.
  o Messages and return codes for whois_database_combined feed
    revised again
  o Introduced the "thin" option to download data for tlds com and net
    from whois_database
    
0.0.22.
  o More consistent messages when downloading multipart archives
    especially from the whois_database_combined feed
    If there is just one file in the feed, the return code will be 2 now,
    otherwise it is zero.
  o Fixed to give 1 (instead of 0) return code for unhandled feed
  o Introduced a --show-progress option to have progress bars for the downloads

0.0.21.
  o More informative error messages
  o Minor code simplification
  o Fixed a but affecting explicit specification of ssl auth files
    in command-line or in variables
  
0.0.20.
  o Fixed some minor bugs
  o Fixed some return codes, to be more coherent with the python version:
    Now
     - return code 2 is for a file which is not found on the server (previously returned 0 or 2 sometimes)
     - in case of success return code 0 is returned (in case of daily feeds it was buggy)
     - return code 1 and those greater than 2 are for abnormal termination

0.0.19.
  o Fixed the following archive feeds to download data
    from the year-named direcotries of past years:
    	 -domain_names_whois_archive
	 -domain_names_whois_filtered_reg_country_archive
	 -domain_names_whois_filtered_reg_country_noproxy_archive
	 -ngtlds_domain_names_whois_archive
	 -ngtlds_domain_names_whois_filtered_reg_country_archive
	 -ngtlds_domain_names_whois_filtered_reg_country_noproxy_archive
  o Added support for the following data feeds:
    	 -domain_names_diff_whois_filtered_reg_country2
	 -cctld_discovered_domain_names_whois_archive
	 -reported_for_removal
  o Implemented a "--list-supported-tlds" option
	 
0.0.18.
  o Added support for ssl key authentication.

0.0.17:
  o Added domain_names_whois2 target.

0.0.16:
  o Handling 403: Forbidden errors in wget
  o Dry run emulates 10 part-files when downloading multipart archives
    (Can be configured with the DRY_RUN_MULTIFILE_LIMIT variable
  o Quarterly downloads require explicit database specifications

0.0.15:
  o Added daily ngtlds feeds such as:
        - ngtlds_domain_names_whois_filtered_reg_country
        - ngtlds_domain_names_whois_filtered_reg_country_noproxy
        - ngtlds_domain_names_whois_archive
        - ngtlds_domain_names_whois_filtered_reg_country_archive
        - ngtlds_domain_names_whois_filtered_reg_country_noproxy_archive

0.0.14:
  o Cctld newly discovered daily data domain_names_new and domain_names_whois added.
  o Cctld newly registered daily data domain_names_new, domain_names_whois, domain_names_dropped,
  and domain_names_dropped_whois added.
  o Fixed a bug with whois_database_combined not working exactly as intended.
  o domain_list_quarterly sql feed fixed

0.0.13:
  o Fixed bug where ngtlds feed was getting an error when downloading supported tlds

0.0.12:
  o Fixed bug where "bad feeds" were not being handled properly.
  o Add file format "all" which downloads all available file formats for a given feed.
  o Added full and sql file formats to domain_names_whois_archive feed.

0.0.11:
  o Added data feed support for domain_names_dropped_whois and ngtlds_domain_names_dropped_whois

0.0.10:
  o Added download support for legacy gtld quarterly data v1 and v2

0.0.9:
  o Input date format fixed. 

0.0.8:
  o Added the feed whois_database_combined. Could not test because auth failed.

0.0.7:
  o Removed the --dry command line options from the tests. Now have to tests,
    ut_whoisdownload with dry run and ft_whoisdownload with full download. 

0.0.6:
  o Added the --tld-file command line option. It it is provided it will expect a
    list of domains (e.g. asia,us,tel) in the file and will use that instead of
    the downloadable tld files.
  o Modified and enhanced the tests to check the new tld download methods.
  o If needed the supported_gtlds files supported_ngtlds are loaded from the
    directory where the script was started. This was wrong in the previous 
    version.
  o Downloading of tlds for the whois_database feed is fixed.

0.0.5:
  o Added the new ways to download tld list. Need to be tested.

0.0.4:
  o All the date formats that are supported by the date(1) utility are now
    supported by the --date option.
  o Because of this I had to re-organize the code and so multiple dates now
    available by using the --date option more than once (e.g. 
    --date="2015-10-20" --date="2015-10-21"). This date change proced to be more
    annoyance than I thought, sorry about that.
  o It is now possible to run the program without the --date option if the
    data feed needs no date to be set.
  o Added the long file format name versions, so from now on regular_csv,
    simple_csv, full_csv and mysqldump fiel formats are also accepted.
  o Some data sources dropped some older dates I used in tests so I had to
    modify my tests and re-run them.

SSL authentication setup
------------------------
Consult README.SSL on how to set up ssl authentication if you have
obtained the required files from WhoisXML API, INC.

If you have set up ssl authentication, you can use the

--auth-type=ssl

instead of the --user and --password options in the examples below.

Examples
--------
Example 1
Downloading the domain_names_new data source for all the top level domains at
one specific date.

    ./whoisdownload.sh \
        --user=demo \
        --password=XXXXXX \
        --date=2018-01-10 \
        --output-dir=./tmp  \
        --data-feeds=domain_names_new


Example 2
Download the ngtlds_domain_names_new for three consecutive days for the
abc and actor domains.

    ./whoisdownload.sh \
        --user=demo \
        --password=XXXXXX \
        --tld="abc actor" \
        --date=2018-01-10 \
        --n=3 \
        --output-dir=./tmp  \
        --data-feeds=ngtlds_domain_names_new


Example 3
Downloading the domain_names_new data source of .aero domain for 14 days
starting at a specific date.

    ./whoisdownload.sh \
        --user=demo \
        --password=XXXXXX \
        --date=2018-01-10 \
        --output-dir=./tmp  \
        --tld=aero \
        --n=14 \
        --data-feeds=domain_names_new


Example 4
Downloading the domain_names_whois data source for all the supported tlds at a
specific date.

    ./whoisdownload.sh \
        --user=demo \
        --password=XXXXXX \
        --date=2018-01-10 \
        --output-dir=./tmp  \
        --data-feeds=domain_names_whois


Example 5
Downloading files for two data sources, two domains and two dates, six
downloads altogether.

    ./whoisdownload.sh \
        --user=demo \
        --password=XXXXXX \
        --output-dir=./tmp  \
        --date="2018-01-20 2018-02-10" \
        --tld="org info" \
        --data-feeds="domain_names_new domain_names_dropped"


Example 6

Download the v20 version of the whois_database for one tld (The date
argument is required but ignored.)

    ./whoisdownload.sh \
        --verbose \
        --user=demo \
        --password=XXXXXX \
        --file-format=simple \
        --db-version=v20 \
        --date=2018-01-01 \
        --tld=tel \
        --output-dir=./tmp \
        --data-feeds=whois_database


Example 7
Download the v19 version of the whois_database for for all tlds.
(The date argument is required but ignored.)

./whoisdownload.sh \
        --verbose \
        --user=demo \
        --password=XXXXXX \
        --file-format=simple \
        --db-version=v19 \
	--date=2018-01-01 \	
        --output-dir=./tmp \
        --data-feeds=whois_database

Example 8
Download the v6 version of the cctld whois_database for for all tlds.
(The date argument is required but ignored.)

    ./whoisdownload.sh \
        --verbose \
        --user=demo \
        --password=XXXXXXX \
        --file-format=simple \
	--date=2018-01-01 \
        --db-version=v6 \
        --output-dir=./tmp \
        --data-feeds=domain_list_quarterly

Example 9
Download the v6 version of the cctld whois_database for for one tld.
(The date argument is required but ignored.)

    ./whoisdownload.sh \
        --verbose \
        --user=demo \
        --password=XXXXXX \
        --file-format=simple \
	--date=2018-01-01 \
        --db-version=v6 \
        --tld=uk
        --output-dir=./tmp \
        --data-feeds=domain_list_quarterly
