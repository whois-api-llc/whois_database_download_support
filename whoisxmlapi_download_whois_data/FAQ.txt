FAQ.txt for

download_whois_data.py

Copyright (c) 2010-2021 Whois API LLC,  http://www.whoisxmlapi.com
-------------------------------------------------------------------

Q1: I  obtained an  error  stating that  my login  and password  are
invalid. I can access the page with my browser. What happened?

A1:  It might be  the case  that you have  specified a wrong  date or
database version. E.g. you chose v20 of quarterly cctld feeds when the
last version is v8. As the script  does not have data on the available
db  versions,  it  derives  file  locations from  the  data  you  have
specified,  but these  locations  do  not exist  on  our server.   For
security reasons the server will  report invalid login credentials, so
it will appear as if there was something wrong with your password.

Please double-check the feed name and the parameters you are using.
--------------------------------------------------------------------

Q2: The  script  says  it cannot  determine  the  list of  supported
tlds. Why?

A2: In spite  of all of our efforts it may  happen that the necessary
supported_tlds file is missing. Please contact support in this case.

--------------------------------------------------------------------

Q3:  The   script  reports   files  which   could  not   have  been
downloaded. When shall they be available?

A3: It  may happen  that some  files derived  according to  the naming
logic of a  given feed do not  exist at the time  of downloading. One
reason might  be that the  file is not yet  prepared when you  run the
script. If  you re-run the script  later with the same  parameters, it
will not  redownload files which are  already there and have  not been
changed, but  it shall find the  missing ones. It may  also occur that
the   file  will   never   exist.   In   feeds   devoted  to   changes
(domain_names_new,  domain_names_dropped),  for   instance,  it  might
happen that there were no changes in the data the given day. We do not
store empty files, so these files will be reported as unavailable, but
this is normal.

--------------------------------------------------------------------

Q4: I  do not  want the script  to check all  supported TLDs  with the
--all-tlds option in case of daily feeds; I want it to try downloading
only for those TLDs  in which there was a change on  the given day and
thus the data file exists.

A4:  Using  the  --only-changed  option will  result  in  the  desired
behavior. It does not work for  all daily feeds, e.g. "delta" feeds do
not support it,  but "new" and "dropped" feeds do.  If downloading for
multiple days,  an attempt will be  made to download data  for all the
TLDs which had a change on at least one of the days.

--------------------------------------------------------------------

Q5:  So far  I have  been using  "download_whois_info.py" which  I had
downloaded for a  release a few years ago. I've  just realized that it
is   not   supported   anymore   and   it   has   been   replaced   by
"download_whois_data". I  decided to  switch the  new script,  but the
options of the  script are different and not compatible.  Why? Can you
make it compatible?

A5:  We decided  to redesign  the  python downloader  in 2017  because
"download_whois_info.py" was  not scalable; initially it  was intended
as a  small example script  but the requirements against  a downloader
script  went  far  beyond  the   original  idea,  so  a  redesign  was
unavoidable.   The  current script  has  many  options and  much  more
capabilities than the  legacy one. So supporting the  legacy and rather
illogical  options  would  lead  tho  an  extremely  large  number  of
options. In addition the operation logic behind the new script is also
different, it is not always possible to map the new options to the old
ones. So it  will not be made compatible, but  the command-line can be
easily rewritten along the following lines:

- old script option: -c
  use --feed instead

- old script option: -l or --login:
  use --username instead

- old script option: -p or --password:
  use --password

- old script option: -d or --date, with YYYY-MM-DD:
  use --startdate with YYYYMMDD

- old script option: --end-date, with YYYY-MM-DD:
  use --enddate with YYYYMMDD

- old script option: -v or --version:
  use --dbversion instead

- old script option: -t, --tld, possibly with a space-separated list
  use --tlds, for more tlds, use a comma-separated list.
  It has no default value. For all tlds, use the --all-tlds options

- old script option: -f
  Use --dataformats instead, a comma-separated list for all formats.
  There is no "all" possibility. Use the --list-dataformats to list
  the available formats for each feed.

- old script option: -odir or --output-dir
  Use --output-dir. It has no default value, hence, it is a mandatory
  argument now.

- old script option: --interactive
  Now it invokes the GUI mode of the script.
  The old function of --interactive is not supported.
  Consult the documentation on how to influence
  redownloading behavior, especially the --maxtries option

- old script option: --no-override
  No such option. Currently if a file is there,
  it will not be downloaded again unless its md5sum
  does not match the file. To redownload,
  delete the respective file.
  
  
